{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring sentence, document, and character-level embedding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously we covered Word Embeddings and Distance Measurements for Text, emphasizing word order and semantics. Now, we extend this to document and sentence embeddings. Doc2Vec captures contextual embeddings for paragraphs, extendable to sentences. Sent2Vec focuses on sentence embeddings via n-grams, preceded by a thorough examination of fastText for word representations using n-grams. Towards the end, an introduction to the Universal Sentence Encoder (USE) is provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Venturing into Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Doc2Vec\" is a natural language processing algorithm that extends the concept of word embeddings to entire documents or paragraphs. It is an extension of the popular Word2Vec model, which generates word embeddings by learning to predict the context of a word within a given window of text. Doc2Vec, introduced by Mikolov et al. in 2014, works similarly but instead learns to generate fixed-length vectors (embeddings) for entire documents or paragraphs. These document embeddings capture the semantic meaning and context of the entire document, enabling various downstream tasks such as document classification, clustering, and similarity retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building paragraph vectors using Doc2Vec\n",
    "Doc2Vec is an extension of Word2Vec that extends the concept of word embeddings to entire documents. It's a powerful technique for representing documents as continuous-valued vectors, which can then be used for various downstream NLP tasks such as document classification, clustering, similarity search, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUeD6iqQrtnA"
   },
   "source": [
    "#### Building a Doc2Vec model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "ddTAUMaspIVn"
   },
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ny4UHwRJryzC",
    "outputId": "118cafcb-64f8-41a8-da59-4459074eb21c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gEqer4Avr09g",
    "outputId": "138db8c4-f7b4-4bcb-f271-2618b5751902"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['human', 'interface', 'computer'], tags=[0]),\n",
       " TaggedDocument(words=['survey', 'user', 'computer', 'system', 'response', 'time'], tags=[1]),\n",
       " TaggedDocument(words=['eps', 'user', 'interface', 'system'], tags=[2]),\n",
       " TaggedDocument(words=['system', 'human', 'system', 'eps'], tags=[3]),\n",
       " TaggedDocument(words=['user', 'response', 'time'], tags=[4]),\n",
       " TaggedDocument(words=['trees'], tags=[5]),\n",
       " TaggedDocument(words=['graph', 'trees'], tags=[6]),\n",
       " TaggedDocument(words=['graph', 'minors', 'trees'], tags=[7]),\n",
       " TaggedDocument(words=['graph', 'minors', 'survey'], tags=[8])]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents=[TaggedDocument(doc,[i]) for i,doc in enumerate(common_texts)]\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T-2EZcAzsM_u",
    "outputId": "6284c3a0-0f8c-4cc2-ca11-2cae8b485a73"
   },
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=5, min_count=1, workers=4,epochs = 40)\n",
    "model.train(documents, total_examples=model.corpus_count,\n",
    "epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y7pfP9h6s3Hh",
    "outputId": "38af50ff-a335-48f7-f276-38edc1dbeba3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9pU1eJaLs9xk",
    "outputId": "267329cf-8792-4ec3-b396-2e8078b582c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2208\\844496226.py:1: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  len(model.docvecs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.docvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OokyLBVctCxE",
    "outputId": "25ec0399-2097-49e5-8b33-ee8e1627391a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fEeicdIhtIQH",
    "outputId": "8dacb3f7-e0b4-4de4-af30-c6d1b5d0dace"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['system',\n",
       " 'graph',\n",
       " 'trees',\n",
       " 'user',\n",
       " 'minors',\n",
       " 'eps',\n",
       " 'time',\n",
       " 'response',\n",
       " 'survey',\n",
       " 'computer',\n",
       " 'interface',\n",
       " 'human']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(model.wv.key_to_index.keys())\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J3z-f2oKtY2g",
    "outputId": "7c6f5d75-1b92-4e78-bb08-a8beb283c9cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0027331 , -0.00960313,  0.05049047, -0.02768766,  0.06817956],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector=model.infer_vector(['user', 'interface', 'for','computer'])\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z02l_G6dvNTq"
   },
   "source": [
    "#### Changing vector size and min_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YFiZ-qttufyg",
    "outputId": "ff79ef76-f43f-41b5-a636-874735c86047"
   },
   "outputs": [],
   "source": [
    "model=Doc2Vec(documents, min_count=3,epochs=40,vector_size=50)\n",
    "model.train(documents, total_examples=model.corpus_count,epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R7wrTizNvptc",
    "outputId": "35fd5cbe-16b6-4c6f-e9d3-eacdb3d8b36d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AGUL6r-tv_D-",
    "outputId": "01f0dea3-7328-4730-b20e-eb7e17f87211"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['system', 'graph', 'trees', 'user']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word=list(model.wv.key_to_index.keys())\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n15DZ9smwJhQ",
    "outputId": "32dcd900-699e-4867-b964-7781605b2761"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00050749, -0.00069027,  0.00566557, -0.00225846,  0.00671367,\n",
       "        0.00243411, -0.00819021, -0.00957174, -0.00364764, -0.0047829 ,\n",
       "       -0.00785492, -0.00024565, -0.00118925, -0.00234127,  0.00762444,\n",
       "        0.0054061 ,  0.00044488,  0.00571045,  0.00824073, -0.00513679,\n",
       "       -0.00990448, -0.00757426,  0.00459863, -0.00892727,  0.00692203,\n",
       "       -0.00593891,  0.00920657,  0.0025982 , -0.00669509,  0.00575561,\n",
       "       -0.00659957,  0.00393462, -0.00810801, -0.00737172,  0.00671644,\n",
       "        0.00493415,  0.004701  ,  0.00752889,  0.00385293,  0.00540007,\n",
       "       -0.00541467, -0.0051679 , -0.00673952,  0.00482542,  0.00345801,\n",
       "       -0.00858704, -0.0058589 , -0.00026754, -0.00943008, -0.00538201],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector=model.infer_vector(['user', 'interface', 'for','computer'])\n",
    "vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-zyKAFgwbpD"
   },
   "source": [
    "As we can see, the vector size is now 50 and only 4 terms are in the vocabulary.\n",
    "This is because min_count was modified to 3 and, consequently, terms that were\n",
    "equal to or greater than 3 terms are present in the vocabulary now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYvBM1lnwki7"
   },
   "source": [
    "Testing two different approaches of doc2vec\n",
    "\n",
    "\n",
    "1.   PV-DM\n",
    "2.   PV-DBOW\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o9tDJEh8wVd2",
    "outputId": "5a65e7ea-c369-4f59-9e29-e287e18f4cb9"
   },
   "outputs": [],
   "source": [
    "model=Doc2Vec(documents,vector_size=50,min_count=2,epochs=40,dm=1)\n",
    "model.train(documents,total_examples=model.corpus_count,epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7w2wSD0xMJh"
   },
   "source": [
    "dm equal to 0 builds the Doc2Vec model based on the distributed bag-of-words approach and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7fM67JhsxG-g",
    "outputId": "38c7c3a0-f46e-4a91-df42-44e865d92cf6"
   },
   "outputs": [],
   "source": [
    "model=Doc2Vec(documents,vector_size=50,min_count=2,epochs=40,dm=0)\n",
    "model.train(documents, total_examples=model.corpus_count,epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3_L4q9HxuWR"
   },
   "source": [
    "The dm_concat parameter is used in the PV-DM approach. Its value, when set to 1,\n",
    "indicates to the algorithm that the context vectors should be concatenated while trying to\n",
    "predict the target word. This, of course, leads to building a larger model since multiple\n",
    "word embeddings get concatenated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V0mhuZLXxjmK",
    "outputId": "c3db0637-b5b7-4ce1-cedf-89726a50e4cc"
   },
   "outputs": [],
   "source": [
    "model=Doc2Vec(documents,vector_size=50,min_count=2,epochs=40,dm=1,window=2,min_alpha=0.005,dm_concat=1)\n",
    "model.train(documents, total_examples=model.corpus_count,epochs=model.epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88hGMJAiZhMQ"
   },
   "source": [
    "The window size parameter controls the distance between the word under concentration\n",
    "and the word to be predicted, similar to the Word2Vec approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s17KfNuxyJA0",
    "outputId": "8e90272d-72fe-4806-9b2f-f3a8ac62440f"
   },
   "outputs": [],
   "source": [
    "model=Doc2Vec(documents,vector_size=50,min_count=2,epochs=40,window=2,dm=0)\n",
    "model.train(documents,total_examples=model.corpus_count,epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9qsO_n3Z_K9"
   },
   "source": [
    "Now, let's explore what the learning rate is and how it can be leveraged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "og0g5JDQaSr9"
   },
   "source": [
    " For Doc2Vec,\n",
    "the initial learning rate can be specified using the alpha parameter. With the min_alpha\n",
    "parameter, we can specify what value the learning rate should drop to over the course of\n",
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yauFO3emZ7PU",
    "outputId": "1ce9c177-909c-409d-b839-0d9658e84ffd"
   },
   "outputs": [],
   "source": [
    "model=Doc2Vec(documents, vector_size=50,min_count=2,epochs=40,alpha=0.3,min_alpha=0.05,window=2,dm=1)\n",
    "model.train(documents, epochs=model.epochs,total_examples=model.corpus_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qP0tCZU_IDj9"
   },
   "source": [
    "#### Exploring fastapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5XQ65zeJAth"
   },
   "source": [
    "Let's see the two- and three-character n-grams for the word language:\n",
    "la, lan, an, ang, ng, ngu, gu, gua, ua, uag, ag, age, ge\n",
    "fastText leads to parameter sharing among various words that have any overlapping n-grams. We capture their morphological information from sub-words to build an\n",
    "embedding for the word itself. Also, when certain words are missing from the training\n",
    "vocabulary or rarely occur, we can still have a representation for them if their n-grams are\n",
    "present as part of other words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9td0eKA4JC5p"
   },
   "source": [
    "Why n-grams are useful:\n",
    "\n",
    "Sharing Similarities: The machine can find connections between words that share these n-gram pieces. For example, \"language\" and \"angle\" both have \"an\" and \"ag\" as n-grams, suggesting they might be related in some way.\n",
    "\n",
    "Understanding Unfamiliar Words: If the machine encounters a new word (like \"lingual\") that it hasn't seen before, it can still make some sense of it because \"lingual\" shares n-grams (\"in\", \"gu\") with words it already knows.\n",
    "\n",
    "Basically, n-grams help the machine learn word meanings by looking at smaller building blocks that can appear in many different words. This is especially useful for rare words or for languages with complex morphology (where words are built from smaller meaningful parts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAjNNVjaJOj0"
   },
   "source": [
    "**Buiding a fasttext model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "uUqXty7aat6E"
   },
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "from gensim.test.utils import common_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q1moPB9qLUMd",
    "outputId": "00c76f45-f3ba-420c-a847-908399108fe3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zKGbOhH3JiMl",
    "outputId": "c18699dd-1894-4a43-c8d2-1a3befebcb09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 290)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FastText(vector_size=5, window=3, min_count=1)\n",
    "\n",
    "model.build_vocab(common_texts)\n",
    "model.train(common_texts, total_examples=len(common_texts), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PddemNiKJ7d8",
    "outputId": "04c36551-3c45-424d-b5f5-96fbd04fcab3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['system',\n",
       " 'graph',\n",
       " 'trees',\n",
       " 'user',\n",
       " 'minors',\n",
       " 'eps',\n",
       " 'time',\n",
       " 'response',\n",
       " 'survey',\n",
       " 'computer',\n",
       " 'interface',\n",
       " 'human']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab=list(model.wv.key_to_index.keys())\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "deYLCipwLwEs",
    "outputId": "bbd410ff-2822-4c3d-d297-07bd870fbe9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03166137,  0.02326731,  0.01241683,  0.00036033,  0.02841445],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['human']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49uzs3pLMu1R",
    "outputId": "e7fd4586-e7fc-4aae-f37d-55f869bd4b44"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('user', 0.7968785762786865),\n",
       " ('system', 0.17462188005447388),\n",
       " ('response', 0.104334257543087),\n",
       " ('survey', 0.009604760445654392),\n",
       " ('trees', -0.07640466839075089),\n",
       " ('time', -0.1330047994852066),\n",
       " ('minors', -0.13927175104618073),\n",
       " ('eps', -0.24093686044216156),\n",
       " ('graph', -0.291752427816391)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['computer','interface'],negative=['human'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lScuNlvINNeV"
   },
   "source": [
    "Since word representations in FastText are built using the n-grams, min_n, and\n",
    "max_n characters, this helps us by setting the minimum and maximum lengths of\n",
    "the character n-grams so that we can build representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x6p-n5-DNFMg",
    "outputId": "478823e6-a47b-4c0d-8f7f-7e4d5d567ce4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 290)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=FastText(vector_size=5,window=3,min_count=1, min_n=1, max_n=5)\n",
    "model.build_vocab(common_texts)\n",
    "model.train(common_texts,total_examples=len(common_texts), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yodUBVXLN4vS",
    "outputId": "3b3358fc-8149-4e8f-f1f7-c3ffaa8dcfb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01833104, -0.02146881,  0.00600105, -0.03445042, -0.0165866 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['rubber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "umnF9HgXN_cu",
    "outputId": "aaceadc0-de08-4cf7-bf3c-6f36b1dbee5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trees', 0.795038104057312),\n",
       " ('eps', 0.7793108820915222),\n",
       " ('minors', 0.2440604716539383),\n",
       " ('time', 0.1623203009366989),\n",
       " ('user', -0.04820726439356804),\n",
       " ('graph', -0.15672056376934052),\n",
       " ('survey', -0.20417772233486176),\n",
       " ('interface', -0.3921482563018799),\n",
       " ('response', -0.6897355914115906),\n",
       " ('system', -0.8435077667236328)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['computer','human'],negative=['rubber'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJ1BcDpNOT-U"
   },
   "source": [
    "#### Extending the built model to incorporate words from new sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "HhARaqRcONfC"
   },
   "outputs": [],
   "source": [
    "sentences_to_be_added = [[\"I\", \"am\", \"learning\", \"Natural\", \"Language\", \"Processing\"],\n",
    "                         [\"Natural\", \"Language\", \"Processing\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JCKXEl6TOo7p",
    "outputId": "714650f7-8612-4ca5-fcb0-e0f156daa5e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 290)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build_vocab(sentences_to_be_added, update=True)\n",
    "model.train(common_texts, total_examples=len(sentences_to_be_added), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZPmGL_ZBOtjT",
    "outputId": "971657b0-458f-4373-b451-6255ee4ef335"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['system',\n",
       " 'graph',\n",
       " 'trees',\n",
       " 'user',\n",
       " 'minors',\n",
       " 'eps',\n",
       " 'time',\n",
       " 'response',\n",
       " 'survey',\n",
       " 'computer',\n",
       " 'interface',\n",
       " 'human',\n",
       " 'I',\n",
       " 'am',\n",
       " 'learning',\n",
       " 'Natural',\n",
       " 'Language',\n",
       " 'Processing']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab=list(model.wv.key_to_index.keys())\n",
    "vocab"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv1kernel",
   "language": "python",
   "name": "venv1kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
